---
layout: post
title: "A Bug's Tale"
comments: true
description: "The story of one particularly interesting bug"
keywords: ".net, dotnet, wcf, bug"
---

Working in a production support role can take you on some wild rides.  At times, hunting down the source of a bug can make
you want to rip out your hair, and even question your sanity.  Quite often though, the harder you work to
unravel a problem, the sweeter the satisfaction when you finally get to the bottom of it.  This is the story of one of those
kind of bugs.  While it may have cost me a few hair folicles, the payoff at the end was worth it. 

### How it all started
I work for a fairly small software development shop.  We support a handful of different products, including
a desktop app that uses WCF to call back home to one of our services.  Out of the blue, we got a report from a user
saying they were getting timeout errors in the desktop software related to some functions that called back to 
our WCF service.  Initially, our support team thought this must be a fluke.  If our service was down, we would have
been flooded with calls.  This was just a single desktop, in an office with several installations.  Being desktop
software, support frequently gets calls from users blaming our software for any and every PC related problem they 
may have.  We hadn't released any updates to this part of the app for months, so support felt pretty confident that
this was not really our problem.

Nonetheless, our company prides itself in customer service, so our support team will try to help as much as they can.
They started to look at the usual suspects when network related errors pop up: antivirus, SSL/TLS cert issues, bad
internet connection.  Nothing obvious turned up.  In the mean time, new reports of this same issue started to come in.
The numbers were small, maybe 20 of our 10,000 or so installs were having problems.  Not enough to make this a critical
issue, but enough that we couldn't write this off as some fluke.

Thats when support called for ["the expert"](https://www.youtube.com/watch?v=BKorP55Aqvg).
Unfortunately, our expert in this area was gone.  He had moved on to another company several months back.  No one else knew much
about this particular area of the code in the desktop app, certainly not me.  I happened to work on the service this code was
calling back to, so naturally, I became the reluctant heir to this problem.

###Digging In
I have worked with WCF enough to know she can be a fickle mistress.  My first thought was some configuration issue.
That led no where.  I have also known WCF to bury the real error message, so switched on trace logging.  Still not much helpful.
The only error in the WCF trace log was:

```csharp
The request channel timed out while waiting for a reply after 00:00:59.8595997. Increase the timeout value passed
to the call to Request or increase the SendTimeout value on the Binding. The time allotted to this operation may
have been a portion of a longer timeout.
```

This wasn't much to go on.  There was no reason for this request to be timing out.  The vast majority of our clients were
able to connect to the service just fine.  I trolled through our server side logs, and couldn't find any evidence that the
requests  from affected clients were ever making it to our servers.  OK, so the the request must be getting dropped
somewhere along the way.  It is not unheard of for an antivirus or firewall to drop requests like this, so we explored that
avenue some more.  We went as far as temporarily disabling the antivirus/firewall on one of the affected machines, but to no avail.

I needed more information.  We were able to get System.Net trace logs and a Wireshark trace.  The System.Net trace showed
a different error:

```csharp
System.Net.Sockets Error: 0 : [1916] Exception in Socket#45648486::Send - An existing connection was forcibly closed by the remote host.
```

